%auto-ignore
\providecommand{\MainFolder}{..}
\documentclass[\MainFolder/Text.tex]{subfiles}

\begin{document}

\section{Gradings, degree shifts and completions
%for the \texorpdfstring{$\IBLInfty$-theory}{IBL-infinity-theory}
}
\label{Sec:Alg1a}

We will work with vector spaces over $\R$, possibly infinite-dimensional, graded by the \emph{degree} $d\in \Z$ and the \emph{weight} $k\in \N_0$.

\begin{Definition}[Weight-graded vector spaces]\label{Def:Grading}
A \emph{graded vector space} is a vector space~$W$ together with a collection  of subspaces $W^d \subset W$ for all $d\in \Z$ such that
$$ W=\bigoplus_{d\in \Z} W^d. $$
Elements of $W^d$ are called \emph{homogenous} of degree $d$; given $w\in W^d$, we denote the degree of $w$ by $\Abs{w} \coloneqq d$. 

A linear map of graded vector spaces $f: W_1 \rightarrow W_2$ is called homogenous of degree $\Abs{f} \in \Z$ if it holds 
\begin{equation}\label{Eq:StdGrading}
f(W_1^d)\subset W_2^{d+\Abs{f}}\quad\text{for all }d\in \Z.
\end{equation}

A \emph{weight-graded vector space} is a graded vector space $W$ together with a collection of subspaces $W_k^d \subset W^d$ for all $k\in \N_0$ and $d\in \Z$ such that
$$ W^d=\bigoplus_{k\in\N_0} W_k^d\quad\text{for all }d\in \Z. $$
We define the \emph{weight-$k$ component} of $W$ by
$$ W_k \coloneqq \bigoplus_{d\in \Z} W_k^d\quad\text{for all }k\in \N_0. $$
If $W_0^d = 0$ for all $d\in \Z$, we say that $W$ is \emph{weight-reduced.} We define the \emph{weight-reduced subspace} $\widebar{W}$ of a weight-graded vector space $W$ by
$$ \widebar{W} \coloneqq \bigoplus_{d\in \Z} \bigoplus_{k\in\N} W_k^d. $$ 


The superscript $\,{}^*$ usually denotes the dual in the category we work in, e.g., chain complexes. For a (weight-)graded vector space $W$, we also introduce the following notation to avoid confusion:%\footnote{This notation is applied only when it is clear that our main focus lies on the way a multi-graded vector space is dualized. Otherwise, ${}^*$ denotes the dualization in whichever category we currently work with and~${}'$ labels objects of the same type.}
\begin{equation}\label{Eq:Duals}\begin{aligned}
W^{\LD} \coloneqq \{\psi: W \rightarrow \R \text{ linear}\} &\;\,\dots&& \text{\emph{linear dual,}}\\[2\jot]
W^{\GD}  \coloneqq \bigoplus_{d\in  \Z} \prod_{k\in \N_0} W_{k}^{d*} &\;\,\dots&& \text{\emph{graded dual,}}\\
W^{\WGD} \coloneqq \bigoplus_{d\in \Z} \bigoplus_{k\in \N_0} W_k^{d*} &\;\,\dots&& \text{\emph{weight-graded dual.}}
\end{aligned}
\end{equation}
Here, $W^{\LD}$ is a vector space, $W^{\GD}$ a graded vector space and $W^{\WGD}$ a weight-graded vector space. The grading convention from \eqref{Eq:Duals} is the \emph{cohomological grading convention}, which differs from the convention \eqref{Eq:StdGrading} for maps $f: W \rightarrow \R$ by degree reversal (for this, see Definition~\ref{Def:DegreeShift}).

We identify $W^{\GD}$ with the subspace of $W^{\LD}$ generated by homogenous maps and~$W^{\WGD}$ with the subspace of $W^{\LD}$ generated by maps which are non-zero only on finitely many~$W_k^d$; hence, under this identification, we have the tower of inclusions 
$$ W^{\WGD} \subset W^{\GD} \subset W^{\LD}.$$
\end{Definition}

% Pick a forgetful functor from the category of weight-graded to the category of graded. And a functor back by embedding graded vector spaces into weight graded.

\begin{Definition}[Koszul sign] \label{Def:Koszul}
Let $k\ge 1$, and let $\sigma\in \Perm_k$ be a permutation on~$k$ elements, i.e., a bijection of the set $\{1,\dotsc,k\}$. For $i=1$, $\dotsc$, $k$,  let $a_i$ and $b_i$ be graded symbols of degrees~$\Abs{a_i}$ and~$\Abs{b_i}$, respectively. We denote by 
$$\varepsilon(\sigma,a) \quad\text{and}\quad\varepsilon(a,b)$$
the \emph{Koszul signs} of the transformations
 $$ a_1 \dots a_k \longmapsto a_{\sigma_1^{-1}} \dots a_{\sigma_k^{-1}} \quad \text{and} \quad a_1 \dots a_k b_1 \dots b_k \longmapsto a_1 b_1 \dots a_k b_k, $$
respectively. Here $\sigma_i^{-1} \coloneqq \sigma^{-1}(i)$. The Koszul sign is computed by permuting the left-hand side to the right-hand side via transpositions of two adjacent elements such that whenever we transpose two graded symbols, e.g., $a_i \longleftrightarrow a_{j}$, we multiply with $(-1)^{\Abs{a_i}\Abs{a_{j}}}$.
\end{Definition}

We emphasize that the Koszul sign depends only on the initial and the final order of the graded symbols and not on the sequence of transpositions; this is easy to show.


%We have
%$$\begin{aligned} 
%W^{\WGD} = W^{\GD} &\Equiv \forall d\in \Z\ \exists I\subset \N_0, \Abs{I}<0\ \forall k\in \N_0 \backslash I:  W_k^d = 0, \\
%W^{\GD} = W^* &\Equiv \exists I \subset \Z, J \subset \N_0, \Abs{I}, \Abs{J}<\infty\ \forall (d,k)\in \Z\times \N_0 \backslash I\times J: W_k^d=0.
%\end{aligned}$$
%In particular, $W^* = W^{\GD} = W^{\WGD}$ if $\Dim(V)<\infty$. 

\begin{Definition}[Degree shift and grading reversal]\label{Def:DegreeShift}
Let $A\in \Z$. The \emph{degree shift by $A$} is a functor which associates to a graded vector space $W$ the graded vector space $W[A]$ with degree-$d$ components
$$ W[A]^d \coloneqq W^{d+A}\quad \text{for all }d\in \Z.$$%In the following remark, we discuss two interpretations of the degree shift.
There is the canonical degree shift morphism 
\begin{equation}\label{Eq:DegreeShift}
 W\longrightarrow W[A]
\end{equation}
of degree $-A$ mapping $W^d$ identically to $W[A]^{d-A}$. We view this morphism as multiplication from the left with a formal symbol $\Susp_A$ of degree $\Abs{\Susp_A}=-A$, so that~\eqref{Eq:DegreeShift} can be written as $w\in W \longmapsto \Susp_A w\in W[A]$.

Given graded vector spaces $W_1$, $W_2$ and constants $A_1$, $A_2\in \Z$, we associate to a morphism $f: W_1 \rightarrow W_2$ its \emph{degree shift} $f: W_1[A_1] \rightarrow W_2[A_2]$ by defining\footnote{This convention is not optimal; see Remark~\ref{Rem:BadConvention}.}
\begin{equation}\label{Eq:DegreeShiftConv}
f(\Susp_{A_1} w) \coloneqq \Susp_{A_2} f(w)\quad\text{for all } w \in W_1.
\end{equation} 
Notice that if $f:W_1 \rightarrow W_2$ has degree $\Abs{f}$, then $f: W_1[A_1] \rightarrow W_2[A_2]$ has degree $\Abs{f} + A_1 - A_2$.

The \emph{grading reversal} $r$ is a functor which associates to a graded vector space~$W$ the graded vector space $r(W)$ with
$$ r(W)^d \coloneqq W^{-d}\quad\text{for all }d\in \Z. $$
There is the canonical morphism $W\rightarrow r(W)$ mapping $W^d$ identically to $W^{-d}$ for every $d\in \Z$. The degree reversal of a morphism $f: W_1 \rightarrow W_2$ is the morphism $f: r(W_1) \rightarrow  r(W_2)$ defined by conjugating $f$ with the canonical morphism. If $\Abs{f}$ is the degree of $f: W_1 \rightarrow W_2$, then $-\Abs{f}$ is the degree of $f: r(W_1) \rightarrow  r(W_2)$.
\end{Definition}

In our main reference \cite{Cieliebak2015}, they view $W$ and $W[A]$ as one vector space with two different gradings $\Deg(\cdot)$ and $\Abs{\cdot}$, respectively; these are related by
\begin{equation*}
%\label{Eq:DegreeRel}
\Abs{w} = \Deg(w) - A \quad\text{for all homogenous }w\in W. 
\end{equation*}
%In particular, writing $w\in W$ and $w\in W[A]$ is for them equivalent.
%This is the ``passive'' point of view on degree shifts.
On the other hand, we think of $W$ and $W[A]$ as of two different graded vector spaces and never use the same symbol for an element $w\in W$ and its degree shift $\Susp_A w \in W[A]$. %It is the ``active'' point of view.
It allows us to use just one notation~$\Abs{\cdot}$ for the gradings on both~$W$ and~$W[A]$. However, in order to preserve compatibility with~\cite{Cieliebak2015}, we will also sometimes use the notation $\Deg(w)$ (in the exponent just $(-1)^w$) for the degrees on $W$.

For graded vector spaces $W_1$, $\dotsc$, $W_k$ and constants $A_1$, $\dotsc$, $A_k\in \Z$, we identify 
$$ W_1[A_1]\otimes \dotsb \otimes W_k[A_k] \simeq (W_1\otimes \dotsb \otimes W_k)[A_1+\dotsb+A_k] $$ using the \emph{Koszul convention for the tensor product}; for homogenous elements $w_1 \in W_1$,~$\dotsc$, $w_k \in W_k$, it reads
\begin{equation} \label{Eq:KoszulTensor}
\Susp_{A_1} w_1 \otimes \dotsb \otimes \Susp_{A_k} w_k = \varepsilon(\Susp_A,w) \underbrace{\Susp_{A_1}\dots\Susp_{A_k}}_{\displaystyle \mathclap{\eqqcolon \Susp_{A_1 + \dotsb + A_k}}\rule{0ex}{2ex}} w_1 \otimes \dotsb \otimes w_k.
\end{equation}
%We understand the product $\Susp_{A_1}\dots\Susp_{A_k}$ as one formal symbol of degree $-(A_1+\dotsb+A_k)$.
%we can abbreviate it by $\Susp_{\vec{A}}\coloneqq \Susp_{A_1} \dots \Susp_{A_k}$, and when $A_1 = \dotsb = A_k$, then we write $\Susp_A^k$ instead.
If $A_1 = \dotsb = A_k \eqqcolon A$ is fixed in the context, which is our usual case, we omit the subscript~$A$ and write just $\Susp$.

In the case of the multilinear map $f: W_1\otimes \dotsb \otimes W_k \rightarrow V_1\otimes \dotsb \otimes V_l$, the combination of~\eqref{Eq:DegreeShiftConv} and~\eqref{Eq:KoszulTensor} gives for $f: W_1[A_1]\otimes \dotsb\otimes W_k[A_k] \rightarrow V_1[B_1]\otimes \dotsb\otimes V_l[B_l]$ the following:
\begin{equation}\label{Eq:DegreeShiftConvII}
 f(\Susp_{A_1 +\dotsb + A_k} w_1 \otimes \dotsb \otimes w_k) = \Susp_{B_1 + \dotsb + B_l} f(w_1 \otimes \dotsb \otimes w_k).
\end{equation}

\begin{Remark}[Why is this sign convention bad?]\label{Rem:BadConvention}
Let us illustrate that \eqref{Eq:DegreeShiftConvII} is not compatible with the following standard Koszul rule:
\begin{equation*}
(K):\qquad (f_1 \otimes f_2)(w_1 \otimes w_2) = (-1)^{\Abs{f_2}\Abs{w_1}} f_1(w_1) \otimes f_2(w_2).
\end{equation*}
On one hand, we get 
$$\begin{aligned}
(f_1 \otimes f_2)(\Susp^2 w_1 \otimes w_2) &\overset{\eqref{Eq:DegreeShiftConvII}}{=} \Susp^2 (f_1\otimes f_2)(w_1 \otimes w_2) \\
& \overset{(K)}{=} (-1)^{\Abs{f_2}\Abs{w_1}} \Susp^2 f_1(w_1) \otimes f_2(w_2)  \\
& \overset{\eqref{Eq:KoszulTensor}}{=} (-1)^{\Abs{f_2}\Abs{w_1} + A(\Abs{f_1} + \Abs{w_1})} \Susp f_1(w_1) \otimes \Susp f_2(w_2).
\end{aligned}$$
On the other hand, we get
$$\begin{aligned}
(f_1 \otimes f_2)(\Susp^2 w_1 \otimes w_2) &\overset{\eqref{Eq:KoszulTensor}}{=} (-1)^{A\Abs{w_1}}(f_1 \otimes f_2)(\Susp w_1 \otimes \Susp w_2)\\
&\overset{(K)}{=} (-1)^{A\Abs{w_1} + \Abs{f_2}(A+\Abs{w_1})} f_1(\Susp w_1) \otimes f_2(\Susp w_2)\\ &\overset{\eqref{Eq:DegreeShiftConvII}}{=}(-1)^{A\Abs{w_1}+ \Abs{f_2}(A+\Abs{w_1})} \Susp f_1(w_1) \otimes \Susp f_2(w_2).
\end{aligned}$$
The results differ by $(-1)^{A(\Abs{f_1}+\Abs{f_2})}$. Therefore, we can not use (K) to identify the tensor product $\Hom(W_1,V_1)\otimes \Hom(W_2,V_2)$ with a subspace of $\Hom(W_1\otimes W_2, V_1\otimes V_2)$ in general. We will rather define an ad-hoc pairing in the case where we need it (see Definition~\ref{Def:Pairings}).

Another caveat is that in the case of the tensor product, the degree shift by $A_1$ followed by the degree shift by~$A_2$ is not the same as the degree shift by $A_1 + A_2$. Indeed, we compute
$$\begin{aligned}
(\Susp_{A_1 + A_2}w_1) \otimes (\Susp_{A_1 + A_2}w_2) &=
(\Susp_{A_2} \Susp_{A_1}w_1) \otimes (\Susp_{A_2}\Susp_{A_1} w_2) \\ &= (-1)^{A_2(A_1 + \Abs{w_1})}\Susp_{A_2}^2 (\Susp_{A_1} w_1) \otimes (\Susp_{A_1} w_2) \\
&= (-1)^{A_2 A_1 + (A_1 + A_2)\Abs{w_1}} \Susp_{A_2}^2 \Susp_{A_1}^2 (w_1 \otimes w_2) \\ &= (-1)^{A_2 A_1 + (A_1 + A_2)\Abs{w_1}} \Susp_{2(A_1 + A_2)} (w_1 \otimes w_2),
\end{aligned}$$
which differs by $(-1)^{A_1 A_2}$ from the direct degree shift by $A_1 + A_2$. Therefore, we have to always remember the vector spaces which we started with and the sequence of degree shifts. 

Note that we also have the unnatural ``$\Susp_{A_1} \Susp_{A_2} = \Susp_{A_1 + A_2} = \Susp_{A_2} \Susp_{A_1}$'' due to \eqref{Eq:KoszulTensor}.
\end{Remark}

\begin{Remark}[Is there a better sign convention?]
The author originally respected the Koszul rule for the algebra with formal symbols and considered the following map $\Susp^{l}_*\widebar{\Susp}^{k*} f: W[A]^{\otimes k} \rightarrow V[A]^{\otimes l}$ as the degree shift of $f: W^{\otimes k} \rightarrow V^{\otimes l}$:
\begin{equation}\label{Eq:AltConv}
(\Susp^{l}_*\widebar{\Susp}^{k*} f)(\Susp^{k} w_1 \otimes \dotsb \otimes w_k ) = (-1)^{k \Abs{f}A + \frac{1}{2}k(k-1) A} \Susp^l f(w_1 \otimes \dotsb \otimes w_k).
\end{equation}
Here $\DeSusp$ denotes the ``inverse'' of $\Susp$ with $\Abs{\widebar{\Susp}} = - \Abs{\Susp}$, $\Susp_*^l f = \Susp^l \circ f$ is the post-composition, $\DeSusp^{k*}f = (-1)^{k A \Abs{f}} f\circ \DeSusp^k$ the pre-composition, and the sign $ \varepsilon(\Susp, \DeSusp) = (-1)^{\frac{1}{2}k(k-1)A}$ comes from the ``collision'' $\DeSusp_1\dots \DeSusp_k \Susp_1 \dots \Susp_k \mapsto \DeSusp_1 \Susp_1 \dots \DeSusp_k \Susp_k$. 

However, the author did not manage to reprove the theory in~\cite{Cieliebak2015} using~\eqref{Eq:AltConv} (because of too many ``external'' signs appearing and a problem with disconnected graphs). A~motivation to try a different sign convention was to explain some artificial signs in~\cite{Cieliebak2015} and formulate their coordinate constructions invariantly in order to generalize them to the ``continuous'' de Rham case.

It might be possible to deduce a ``universal'' sign convention ``respecting'' the Koszul rules by considering the category of chain complexes and graded morphisms $\mathcal{C}$ as the category enriched in the closed monoidal category of chain complexes and chain maps of degree~$0$. One can then define the enriched degree shift functor $\Susp_{A}: \mathcal{C} \rightarrow \mathcal{C}$, embed $\mathcal{C}^{\otimes k} \subset \mathcal{C}$ using~$(K)$ and study enriched natural transformations in the algebra of functors consisting of tensor products and compositions of $\Susp_{A}$, $\Hom(\cdot, \cdot)$ and the dual $*$. The question is whether the sign rules for degree shifts, in particular  \eqref{Eq:AltConv}, are uniquely determined by the requirements on enriched functors and enriched natural transformations.

Another idea for how to specify the degree shift convention~\eqref{Eq:AltConv} is the observation that maps $f: W^{\otimes k}\rightarrow W^{\otimes l}$ under consideration usually form an algebra $\Prop \rightarrow \End_W$ of a certain PROP $\Prop$ over $W$; here $\End_W$ denotes the endomorphism PROP. Suppose that there is a natural notion of the degree shift $\Prop[A]$ of a PROP $\Prop$ and a canonical degree shift morphism $\Prop \rightarrow \Prop[A]$. The PROPs $(\End_W)[A]$ and $\End_{W[A]}$ are better to be isomorphic, and any intelligent degree shift convention $\psi_{k,l}: \Hom(W^{\otimes k},W^{\otimes l})[A(k-l)] \rightarrow \Hom(W[A]^{\otimes k},W[A]^{\otimes l})$ should induce an isomorphism of the PROPs $(\End_W)[A]$ and $\End_{W[A]}$.
\end{Remark}
%We will also use two different formal symbols $\Susp$ and $\SuspU$ to shift the degrees.
%\begin{Question}
%Is it possible to reprove \cite{Wieliebak2015} using \eqref{Eq:AltWonv}?
%\end{Question}

\begin{Definition}[Standard action of permutations]\label{Def:Permutations}
For $k\ge 1$ and $\sigma\in \Perm_k$ ($\coloneqq$\,the group of permutations on $k$ elements), we define the \emph{standard action of $\sigma$} on $W^{\otimes k}$ by 
\begin{equation}\label{Eq:Perm}
\sigma(w_1 \otimes \dotsb \otimes w_k) \coloneqq  \varepsilon(\sigma,w) w_{\sigma_1^{-1}}\otimes \dotsb \otimes w_{\sigma_k^{-1}}
\end{equation}
for all homogenous $w_1$, $\dotsc$, $w_k\in W$.
\end{Definition}

Notice that the $i$-th vector is permuted to the $\sigma_i$-th place --- this is the ``active'' convention for permutations.


\begin{Definition}[Symmetric algebra]\label{Def:SymAlgebra}
Let $\Ten(V)\coloneqq \bigoplus_{k\ge 0} V^{\otimes k}$ be the tensor algebra over a graded vector space~$V$. The \emph{symmetric algebra} over $V$ is defined by $\Sym(V)\coloneqq \bigoplus_{k\ge 0} \Sym_k(V)$, where
$$ \Sym_k(V) \coloneqq V^{\otimes k} \bigl/ \sum_{\sigma\in \Perm_k} \Im(\Id-\sigma)\quad(\eqqcolon \Perm_k\text{-coinvariants}). $$
It is a weight-graded vector space with components denoted by $(\Sym_k V)^d$ for all $d\in \Z$ and $k\in \N_0$. Note that $\Sym_0 V = \R$ has degree $0$ by definition. Consider the canonical projection
$$\begin{aligned}
\pi : \Ten(V) &\longrightarrow \Sym(V) \\
v_1\otimes \dotsb \otimes v_k &\longmapsto v_1\dotsb v_k.
\end{aligned}$$
%The dot $\cdot$ indicates the symmetric product.
If $v_i\in V$ are homogenous, we call $v_1 \dotsb v_k$ a \emph{generating word}; we have
$$ v_1 \dotsb  v_k = \varepsilon(\sigma,v) v_{\sigma_1^{-1}} \dotsb v_{\sigma_k^{-1}}\quad \text{for every }\sigma\in \Perm_k. $$
Let $\iota: \Sym(V) \rightarrow \Ten(V)$ be the section of $\pi$ defined by 
$$ \iota(v_1\dotsb v_k) \coloneqq \frac{1}{k!}\sum_{\sigma\in\Perm_k} \varepsilon(\sigma,v) v_{\sigma_1^{-1}}\otimes \ldots \otimes v_{\sigma_k^{-1}}. $$
We use it to identify $\Sym(V)$ with the subspace of symmetric tensors
$$ \iota(\Sym_k(V)) = \bigcap_{\sigma\in \Perm_k} \Ker(\Id - \sigma) \subset \Ten_k(V)\quad(\eqqcolon\Perm_k\text{-invariants}). $$
\end{Definition}


\begin{Definition}[Filtrations] \label{Def:Filtrations}
Let $W$ be a graded vector space. A filtration of~$W$ is a collection of linear subspaces $\Filtr^\lambda W \subset W$ for $\lambda\in \R$ such that we have either
\begin{itemize}
\item $\Filtr^{\lambda_1}W\subset \Filtr^{\lambda_2}W$ for all $\lambda_1 \le \lambda_2$\quad$\Longleftrightarrow:$\quad\emph{increasing filtration}, or
\item  $\Filtr^{\lambda_1}W\supset \Filtr^{\lambda_2}W$ for all $\lambda_1 \le \lambda_2$\quad$\Longleftrightarrow:$\quad\emph{decreasing filtration.}
\end{itemize}
We will assume that our filtrations are \emph{graded} in the following sense:
$$ \forall \lambda\in \R:\quad \Filtr^\lambda W = \bigoplus_{d\in \Z} \Filtr^\lambda W^d,\quad \text{where}\quad\Filtr^\lambda W^d \coloneqq \Filtr^\lambda W \cap W^d.$$
A filtration $\Filtr^\lambda W$ is called:
\begin{align*}
 \text{\emph{exhaustive}}&\quad:\Equiv\quad\bigcup_{\lambda\in \R} \Filtr^\lambda W = W;\\
 \text{\emph{Hausdorff}} &\quad:\Equiv\quad\bigcap_{\lambda\in \R} \Filtr^\lambda W = 0;\\
 \text{\emph{$\Z$-gapped}} &\quad:\Equiv\quad\Filtr^\lambda W = \Filtr^{\lfloor\lambda\rfloor} W\text{ for all }\lambda \in \R;\\[3\jot]
 \text{\emph{bounded from below}}&\quad:\Equiv\quad\exists \lambda \in \R: \Filtr^\lambda W =0;\\[3\jot]
 \text{\emph{bounded from above}}&\quad:\Equiv\quad\exists \lambda\in \R: \Filtr^\lambda W =W.
\end{align*} 

Given a graded vector space $W$ filtered by a $\Z$-gapped filtration $\Filtr^\lambda W$, we associate to it the bi-graded vector space 
$$ \Gr(W) = \bigoplus_{d\in\Z}\bigoplus_{\lambda\in \Z} \Gr(W)_\lambda^d $$
called the \emph{graded module} whose components are given as follows:\footnote{The definition is made in such a way that if $r$ is the functor which reverses $\lambda$, i.e., $r(\Filtr)^\lambda = \Filtr^{-\lambda}$, then it holds $r(\Gr(\Filtr)) = \Gr(r(\Filtr))$. }\Modify[caption={DONE Graded module},noline]{Should not the grading of $\Gr$ be shitfted? I propose $gr_k = F_k/F_{k\pm 1}$ because $r(gr(\tilde{F})) = gr(F)$ for the degree reversed filtration.}
$$ \forall d, \lambda\in \Z: \quad \Gr(W)_\lambda^d \coloneqq \begin{cases}
                   \Filtr^\lambda W^d /\Filtr^{\lambda-1} W^d & \text{for increasing }\Filtr^\lambda W,\\
                   \Filtr^{\lambda} W^d / \Filtr^{\lambda+1} W^d & \text{for decreasing } \Filtr^\lambda W.
                 \end{cases}$$
We naturally extend a filtration over degree shifts, graded duals, direct sums, tensor products and symmetric products as follows: \allowdisplaybreaks
\begin{align*}
\Filtr^\lambda W[A]^d &\coloneqq \Filtr^\lambda W^{d+A},\\[3.5\jot]
\Filtr^\lambda (W^{\GD})^d &\coloneqq \{\psi\in W^{d*} \mid \Restr{\psi}{\Filtr^\lambda W} = 0\}, \\[3.5\jot]
\Filtr^\lambda\bigl(\bigoplus_{i\in I} W_i\bigr)^d &\coloneqq \bigoplus_{i\in I} \Filtr^{\lambda} W_i^d, \\[2\jot]
\Filtr^{\lambda}(W_1 \otimes \dotsb \otimes W_k)^d &\coloneqq \bigoplus_{\substack{d_1, \dotsc, d_k\in \Z \\ d_1 + \dotsb + d_k = d}}\ \sum_{\substack{\lambda_1, \dotsc, \lambda_k \in \R \\ \lambda_1 + \dotsb + \lambda_k = \lambda}} \Filtr^{\lambda_1} W_1^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} W_k^{d_k},\\
\Filtr^\lambda (\Sym_k V)^d &\coloneqq \pi(\Filtr^\lambda(V^{\otimes k})^d),
\end{align*}
where $\pi: \Ten(V) \rightarrow \Sym(V)$ is the canonical projection. The ground field $\R$ is filtered by the trivial filtration:
\begin{equation}\label{Eq:TrivFiltr}
\Filtr^\lambda \R \coloneqq \begin{cases} \R & \lambda\le 0, \\ 0 & \lambda >0. \end{cases}
\end{equation}
If $(W,\Bdd)$ is a filtered chain complex, we filter the homology as follows:
$$ \forall \lambda \in \R, d\in \Z: \quad \Filtr^\lambda \H_d(W,\Bdd) \coloneqq \{\alpha \in \H_d(C,\Bdd) \mid \exists w\in \alpha: w\in \Filtr^\lambda W^d \}. $$
\end{Definition}

\begin{Definition}[Completions]\label{Def:Completion}
Let $W$ be a graded vector space filtered by a decreasing filtration $\Filtr^\lambda W$. The \emph{filtration degree} of $w\in W$ is defined by
$$ \Norm{w} \coloneqq \sup\{ \lambda\in \R \mid w\in \Filtr^\lambda W\}. $$
The filtration degree of a linear map $f: W_1 \rightarrow W_2$ is defined by
$$ \Norm{f} \coloneqq \sup \{ \lambda\in \R \mid \Norm{f(w)} \ge \Norm{w} + \lambda\ \forall w\in W_1\}. $$
We say that the \emph{filtration degree is finite} if $\Norm{f}>-\infty$. Note that $\Norm{0} = \infty$.

The \emph{completion} of $W$ is the graded vector space
$$ \hat{W}\coloneqq \bigoplus_{d\in \Z} \hat{W}^d, $$
where for all $d\in \Z$  we define
$$ \hat{W}^d \coloneqq \Bigl\{ \sum_{i=0}^\infty w_i\ \Bigl|\   \forall i\in \N_0: w_i\in W^d; \Norm{w_i} \to \infty \text{ as }i\to \infty \Bigl\}\Bigl/\sim.
% \in \Filtr^{\lambda_i} W^d, \lambda_i \rightarrow \infty\text{ as }i\to \infty\Bigr\} \Bigl/ \sim.
$$
Here $\sum_{i=0}^\infty w_i \sim \sum_{i=0}^\infty w_i'$ if and only if $\Norm{\sum_{i=0}^n (w_i - w_i')}\to \infty$ as $n\to \infty$.\footnote{\label{Footnote:Compl}In fact, $\hat{W}$ is the inverse limit $\varprojlim_\lambda^{\mathrm{gr}}(W/\Filtr^\lambda W)$ in the category of graded vector spaces and~$\hat{W}^d$ the inverse limit $\varprojlim_\lambda(W^d/\Filtr^\lambda W^d)$ in the category of vector spaces. As a side-remark, if we forget the grading on $W$, we might also consider $\varprojlim_\lambda (W/\Filtr^\lambda W)$, which would be a vector space containing~$\hat{W}$ as a subspace\vphantom{$W^d$}.}
The completion~$\hat{W}$ is canonically filtered by the filtration $\Filtr^\lambda \hat{W}$ defined as follows:
$$ \forall \lambda\in \R, d\in \Z: \quad \Filtr^\lambda\hat{W}^d\coloneqq \Bigl\{\sum_{i=0}^\infty w_i \in \hat{W}^d \ \Bigr|\ \forall i\in \N_0: w_i \in \Filtr^\lambda W^d \Bigr\}. $$
We denote the completion of $W_1 \otimes \dotsb \otimes W_k$ by $W_1 \COtimes \dotsb \COtimes W_k$ and the completion of $\Sym_k V$ by $\hat{\Sym}_k V$. 


A map $f: W_1 \rightarrow W_2$ of finite filtration degree
\emph{extends continuously} to a linear map $f: \hat{W}_1 \rightarrow \hat{W}_2$; this continuous extension is defined by
$$ f\Bigl(\sum_{i=0}^\infty w_i\Bigr)\coloneqq \sum_{i=0}^\infty f(w_i)\quad\text{for all }\sum_{i=0}^\infty w_i \in \hat{W}. $$
%For all $k\ge 0$, we denote by $\hat{E}_k W$ the completion of the graded vector space~$E_k W$ with respect to the filtration
%$$ \Filtr_\lambda E_k W = \sum_{\substack{\lambda_1, \dotsc, \lambda_k\in \R \\ \lambda_1+ \dotsb + \lambda_k = \lambda}} \pi(\Filtr_{\lambda_1}W[1] \otimes \dotsb \otimes \Filtr_{\lambda_k}W[1]), $$
%where $\pi: W[1]^{\otimes k} \rightarrow E_k W$ is the canonical projection. We set $\hat{E}_0 W \coloneqq \R$.
\end{Definition}

\begin{Remark}[Completed tensor product]\label{Rem:ComplTens}
Using Proposition~\ref{Prop:IsoCrit} below, one can show that the \emph{completed tensor product} $\COtimes$ is associative and that $W_1 \COtimes W_2 \simeq \hat{W}_1 \COtimes \hat{W}_2$. By refining this argument, one can show that $\hat{\Sym}_k V \simeq \hat{\Sym}_k\hat{V}$ for any $k\in \N$.
\end{Remark}

A weight-graded vector space $W$ is canonically \emph{filtered by weights:}
\begin{equation}\label{Eq:FiltrWeights}
\forall \lambda\in \R, d\in \Z:\quad\Filtr^\lambda W^d \coloneqq \bigoplus_{k\le \lambda} W_k^d.
\end{equation}
This filtration is $\Z$-gapped, exhaustive, Hausdorff, increasing and bounded from below. The induced filtration on the graded dual $W^{\GD}$ is $\Z$-gapped, Hausdorff, decreasing and bounded from above (and thus automatically exhaustive). It holds $\Gr(W) \simeq W$, and it is easy to see from \eqref{Eq:Duals} that the canonical map $W^{\WGD} \rightarrow W^{\GD}$ induces the isomorphism
$$ \widehat{W^{\WGD}} \simeq W^{\GD}. $$
We also see that the condition
$$ (WG0): \quad \forall d\in \Z\ \exists J\subset \N_0, \Abs{J}<\infty\ \forall k\in \N_0\backslash J: \quad W_k^d = 0 $$
is equivalent to $W^{\WGD}= W^{\GD}$.

A useful tool to compare completions is the following proposition:

\begin{Proposition}[{\cite[Proposition 7.3.7]{Fresse}}, Isomorphism criterion]\label{Prop:IsoCrit}
Let $W_1$ and~$W_2$ be graded vector spaces filtered by $\Z$-gapped filtrations which are decreasing and bounded from above. Suppose that $f: W_1 \rightarrow W_2$ is a filtration preserving homogenous linear map. Then the continuous extension $f: \hat{W}_1 \rightarrow \hat{W}_2$ is an isomorphism if and only if the induced map $f: \Gr(W_1) \rightarrow \Gr(W_2)$ is an isomorphism.
\end{Proposition}
\begin{proof}
The implication from the right to the left is obtained from the diagram 
$$\begin{tikzcd}
0 \arrow{r} & \Gr(W_1)_\lambda \arrow[hook]{r} \arrow{d}{f} & W_1/\Filtr^{\lambda + 1}W_1 \arrow[two heads]{r} \arrow{d}{f} & W_1/\Filtr^{\lambda} W_1 \arrow{r}   \arrow{d}{f} & 0 \\
0 \arrow{r} & \Gr(W_2)_\lambda \arrow[hook]{r} & W_2/\Filtr^{\lambda+1}W_2 \arrow[two heads]{r} & \arrow{r}W_2/\Filtr^{\lambda} W_2   & 0
\end{tikzcd}$$
by induction using the definition of $\hat{W}$ as the inverse limit of $W/\Filtr^\lambda W$ (see Footnote \ref{Footnote:Compl} on page \pageref{Footnote:Compl}). The other implication follows from $\Filtr^\lambda\hat{W}/\Filtr^{\lambda-1}\hat{W}\simeq\Filtr^\lambda W/\Filtr^{\lambda-1}W$.
\end{proof}


For a graded vector space $W$ filtered by a $\Z$-gapped filtration, consider the following conditions:
\begin{equation}\label{Eq:WGs}
\begin{aligned}
(WG1):\quad& \forall \lambda\in \Z\ \exists I \subset \Z, \Abs{I}<\infty\ \forall d\in \Z\backslash I:& \Gr(W)_\lambda^d &= 0, \\
(WG2):\quad & \forall d, \lambda\in \Z:& \dim(\Gr(W)_\lambda^d) &< \infty.
\end{aligned}
\end{equation}

\begin{Lemma}[Completion of symmetric powers of the graded dual]\label{Lem:Terrible}
Let $W$ be a graded vector space filtered by an exhaustive $\Z$-gapped filtration~$\Filtr^\lambda W$ which is increasing and bounded from below. If (WG1) \& (WG2) are satisfied, then the natural map $\Sym_k(W^{\GD}) \rightarrow (\Sym_k W)^{\GD}$ induces the isomorphism 
$$ \hat{\Sym}_k(W^{\GD}) \simeq  (\Sym_k W)^{\GD} \quad\text{for every }k\in \N.$$
Note that we filter graded duals by the induced filtration from Definition~\ref{Def:Filtrations}.
\end{Lemma}
\begin{proof}
The natural map $\Sym_k(W^{\GD}) \rightarrow (\Sym_k W)^{\GD}$ is clearly filtration preserving, and hence it extends continuously to a map of completions. The target space $(\Sym_k W)^{\GD}$ is already complete (the dual space $W^{\GD}$ is complete, provided that the filtration of~$W$ is exhaustive), and thus we obtain the map $\hat{\Sym}_k(W^{\GD}) \rightarrow (\Sym_k W)^{\GD}$. According to Proposition~\ref{Prop:IsoCrit}, this map is an isomorphism if and only if the induced map $\Gr(\Sym_k(W^{\GD})) \rightarrow \Gr((\Sym_k W)^{\GD})$ is. This is shown by the following computation (the maps involved are natural in at least one direction):
%We will show that it is an isomorphism in the following paragraph.
%Let $d$, $\lambda\in \Z$. In the following computation, we will use the notation 
%$$ \vec{d} \coloneqq (d_1, \dotsc, d_k), \quad \bigoplus_{\Abs{\vec{d}} = d} \dotsb = \bigoplus_{\substack{d_1, \dotsc, d_k \in\Z \\ d_1 + \dotsb + d_k = d}} \dotsb$$
%and likewise for $\lambda$ instead of $d$ and $\sum$ instead of $\oplus$. We will not write down the maps because every indicated isomorphism is natural at least in one direction. We compute:
\allowdisplaybreaks
\begin{align*} 
\frac{\Filtr^\lambda ({W^{\otimes k}}^{\GD})^d}{\Filtr^{\lambda+1} ({W^{\otimes k}}^{\GD})^d} &\simeq \frac{\Filtr^\lambda (W^{\otimes k})^{d*}}{\Filtr^{\lambda+1} (W^{\otimes k})^{d*}} \simeq  \Bigl(\frac{\Filtr^{\lambda+1}(W^{\otimes k})^d}{\Filtr^{\lambda}(W^{\otimes k})^d}\Bigr)^* \\ 
 &\simeq \Biggl( \frac{\bigoplus_{\Abs{\vec{d}}= d} \sum_{\Abs{\vec{\lambda}}= \lambda + 1} \Filtr^{\lambda_1} W^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} W^{d_k}}{\bigoplus_{\Abs{\vec{d}} = d}\sum_{\Abs{\vec{\lambda}} = \lambda} \Filtr^{\lambda_1} W^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} W^{d_k}}\Biggr)^* \\
&\simeq \Biggl( \bigoplus_{\Abs{\vec{d}}= d} \frac{\sum_{\Abs{\vec{\lambda}} = \lambda + 1} \Filtr^{\lambda_1} W^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} W^{d_k}}{\sum_{\Abs{\vec{\lambda}} = \lambda} \Filtr^{\lambda_1} W^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} W^{d_k}}\Biggr)^* \\
&\simeq\Bigl( \bigoplus_{\Abs{\vec{d}} = d} \bigoplus_{\Abs{\vec{\lambda}}=\lambda} \frac{\Filtr^{\lambda_1 + 1}W^{d_1}}{\Filtr^{\lambda_1} W^{d_1}} \otimes \dotsb \otimes \frac{\Filtr^{\lambda_k+1}W^{d_k}}{\Filtr^{\lambda_k} W^{d_k}}\Bigr)^*\\
&\simeq\Bigl( \bigoplus_{\Abs{\vec{\lambda}}=\lambda} \bigoplus_{\Abs{\vec{d}} = d} \frac{\Filtr^{\lambda_1 + 1} W^{d_1}}{\Filtr^{\lambda_1} W^{d_1}} \otimes \dotsb \otimes \frac{\Filtr^{\lambda_k + 1} W^{d_k}}{\Filtr^{\lambda_k} W^{d_k}}\Bigr)^* \\
&\mathclap{\substack{\Z-\text{gapped}  \\[1ex] \&\ \text{bounded below}  \\[1ex] \&\ (WG1)}\rightarrow\rule{7.7em}{0pt}}\simeq  \bigoplus_{\Abs{\vec{\lambda}}= \lambda} \bigoplus_{\Abs{\vec{d}} = d} \Bigl( \frac{\Filtr^{\lambda_1 + 1} W^{d_1}}{\Filtr^{\lambda_1} W^{d_1}} \otimes \dotsb \otimes \frac{\Filtr^{\lambda_k + 1} W^{d_k}}{\Filtr^{\lambda_k} W^{d_k}}\Bigr)^* \\
&\mathclap{{\scriptstyle (WG2)}\rightarrow\rule{4em}{0pt}}\simeq  \bigoplus_{\Abs{\vec{\lambda}}= \lambda} \bigoplus_{\Abs{\vec{d}} = d}  \Bigl( \frac{\Filtr^{\lambda_1 + 1} W^{d_1}}{\Filtr^{\lambda_1} W^{d_1}}\Bigr)^* \otimes \dotsb \otimes \Bigl( \frac{\Filtr^{\lambda_k + 1} W^{d_k}}{\Filtr^{\lambda_k} W^{d_k}}\Bigr)^* \\
&\simeq \bigoplus_{\Abs{\vec{d}} = d} \bigoplus_{\Abs{\vec{\lambda}}=\lambda} \frac{\Filtr^{\lambda_1}(W^{\GD})^{d_1}}{\Filtr^{\lambda_1 + 1}(W^{\GD})^{d_1}}\otimes \dotsb \otimes \frac{\Filtr^{\lambda_k}(W^{\GD})^{d_k}}{\Filtr^{\lambda_k + 1}(W^{\GD})^{d_k}} \\
%&\simeq \bigoplus_{\Abs{\vec{d}} = d} \frac{\sum_{\Abs{\vec{\lambda}} = \lambda} \Filtr^{\lambda_1} (W^{\GD})^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} (W^{\GD})^{d_k}}{ \sum_{\Abs{\vec{\lambda}} = \lambda + 1 } \Filtr^{\lambda_1} (W^{\GD})^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} (W^{\GD})^{d_k} } \\
%&\simeq \frac{\bigoplus_{\Abs{\vec{d}} = d} \sum_{\Abs{\vec{\lambda}} = \lambda} \Filtr^{\lambda_1} (W^{\GD})^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} (W^{\GD})^{d_k}}{\bigoplus_{\Abs{\vec{d}}= d} \sum_{\Abs{\vec{\lambda}} = \lambda + 1 } \Filtr^{\lambda_1} (W^{\GD})^{d_1} \otimes \dotsb \otimes \Filtr^{\lambda_k} (W^{\GD})^{d_k} }  \\
&\simeq \frac{\Filtr^{\lambda} ({W^{\GD}}^{\otimes k})^d}{\Filtr^{\lambda + 1} ({W^{\GD}}^{\otimes k})^d}.
\end{align*}
In fact, this computation shows that $\hat{\Ten}_k(W^{\GD}) \simeq (\Ten_k W)^{\GD}$. The conclusion for $\Sym_k$ follows by checking that the maps above are $\Perm_k$-equivariant.
%
%As for $\Sym_k$,
%%using the maps~$\iota$ and~$\pi$ from Definition~\ref{Def:SymAlgebra}
%we have
%$$ \Filtr^\lambda (\Sym_k(W^{\GD})) \simeq \Filtr^\lambda ({W^{\GD}}^{\otimes k}) / \Perm_k \quad \text{and}\quad \Filtr^\lambda (\Sym_k W)^{\GD} \simeq \Filtr^\lambda ({W}^{\otimes k})^{\GD} / \Perm_k. $$
%It is easy to check that the isomorphisms in the computation above are equivariant with respect to the action of $\Perm_k$. It follows that
%$$ \frac{\Filtr^\lambda (\Sym_k (W^{\GD}))^d}{\Filtr^{\lambda+1} (\Sym_k (W^{\GD}))^d} \simeq \frac{\Filtr^\lambda ({W^{\GD}}^{\otimes k})^d }{\Filtr^{\lambda+1} ({W^{\GD}}^{\otimes k})^d}\Bigr/ \Perm_k \simeq \frac{\Filtr^\lambda (W^{\otimes k})^{\GD}}{\Filtr^{\lambda +1} (W^{\otimes  k})^{\GD}} \Bigr/ \Perm_k \simeq \frac{\Filtr^\lambda {(\Sym_k W)^{\GD}}^d}{\Filtr^{\lambda+1} {(\Sym_k W)^{\GD}}^d}. $$
%This proves the lemma.
%%We used here the general fact that if a group $G$ acts on a vector space $V$ by linear maps and $W\subset V$ is an invariant subspace, then $(V/G)/(W/G) \simeq (V/W)/G$.
%%The only if part holds because $(W\otimes W)^* = W^* \otimes W^*$ iff $\Dim(W)<\infty$ and $(\bigoplus_{i\in I} W_i )^* \simeq \bigoplus_{i\in I} W_i^*$ iff $W_i = 0$ for all but finitely many $i\in I$.
\end{proof}

Given a chain complex $(W,\Bdd)$, the boundary operator $\Bdd$ induces the boundary operator $\Bdd_k : W^{\otimes k} \rightarrow W^{\otimes k}$ for all $k\in \N$; for all $w_1$, $\dotsc$, $w_k\in W$, it is defined~by
\begin{equation}\label{Eq:BddExt}
\Bdd_k(w_1 \otimes \dotsb \otimes w_k)\coloneqq \sum_{i=1}^k (-1)^{\Abs{w_1} + \dotsb + \Abs{w_{i-1}}} w_1 \otimes \dotsb \otimes \Bdd w_i \otimes \dotsb \otimes w_k.
\end{equation}
The map $\Bdd_k$ is clearly $\Perm_k$-equivariant, and thus induces the boundary operator $\Bdd_k : \Sym_k W \rightarrow \Sym_k W$.

\begin{Proposition}[K\"unneth formula for completed symmetric cohomology]\label{Prop:Kuenneth}
Let $(W,\Bdd)$ be a $\Z$-graded chain complex over $\R$ filtered by an exhaustive $\Z$-gapped filtration~$\Filtr^\lambda W$ which is increasing and bounded from below. Consider the dual cochain complex $(W^{\GD},\Dd\coloneqq \Bdd^*)$. Suppose that $\Dd$ has finite filtration degree, so that $\Dd_k: \Sym_k(W^{\GD}) \rightarrow \Sym_k(W^{\GD})$ extends continuously to $\Dd_k : \hat{\Sym}_k(W^{\GD}) \rightarrow \hat{\Sym}_k(W^{\GD})$ for every $k\in \N$. If (WG1) \& (WG2) are satisfied, then the natural map $\Sym_k \H(W^{\GD},\Dd) \rightarrow \H(\hat{\Sym}_k(W^{\GD}),\Dd_k)$ induces the isomorphism
\begin{equation*}
%\label{Eq:TTerrible}
\hat{\Sym}_k \H(W^{\GD},\Dd) \simeq \H(\hat{\Sym}_k(W^{\GD}), \Dd_k)\quad \text{for all }k\in \N.
\end{equation*}
\end{Proposition}
\begin{proof}
The natural map $\Sym_k \H(W^{\GD},\Dd) \rightarrow \H(\hat{\Sym}_k W^{\GD},\Dd_k)$ is clearly filtration preserving, and hence it extends continuously to a map of completions. The target space $\H(\hat{\Sym}_k W^{\GD},\Dd_k)$ is already complete (the homology of a complete space is complete), and hence we obtain the map $\hat{\Sym}_k \H(W^{\GD},\Dd) \rightarrow \H(\hat{\Sym}_k W^{\GD},\Dd_k)$. The following facts are easy to verify:
\begin{enumerate}[label=(\arabic*)]
 \item The isomorphism from Lemma~\ref{Lem:Terrible} is an isomorphism of cochain complexes 
 $$ (\hat{\Sym}_k W^{\GD}, \Dd_k) \simeq ((\Sym_k W)^{\GD}, \Bdd_k^*). $$
\item If the filtration on~$W$ satisfies (WG1) and (WG2), then the filtration on $\H(W)$ also satisfies (WG1) and (WG2), respectively. Consequently, Lemma~\ref{Lem:Terrible} holds for symmetric powers of $\H(W,\Bdd)^{\GD}$ as well.
\item The KÃ¼nneth formula $\H(W^{\otimes k}) \simeq \H(W)^{\otimes k}$ implies $\H(\Sym_k W) \simeq \Sym_k \H(W)$ for any $\Z$-graded chain complex $W$ over $\R$.
\item We have $(\H(W))^{\GD} \simeq \H(W^{\GD})$ over $\R$ by the universal coefficient theorem.
\end{enumerate}
Now, we compute
\begin{align*}
\H(\hat{\Sym}_k W^{\GD},\Dd_k ) &
\underset{\substack{\uparrow\rule{0pt}{1.5ex} \\ (1)}}{\simeq}
\H((\Sym_k W)^{\GD}, \Bdd_k^*)
\underset{\substack{\uparrow\rule{0pt}{1.5ex} \\ (4)}}{\simeq}
\H(\Sym_k W, \Bdd_k)^{\GD} 
\underset{\substack{\uparrow\rule{0pt}{1.5ex} \\ (3)}}{\simeq}
(\Sym_k \H(W,\Bdd))^{\GD} \\ 
&\underset{\substack{\uparrow\rule{0pt}{1.5ex} \\ (2)}}{\simeq}
\hat{\Sym}_k (\H(W,\Bdd)^{\GD}) 
\underset{\substack{\uparrow\rule{0pt}{1.5ex} \\ (4)}}{\simeq}
\hat{\Sym}_k \H(W^{\GD},\Dd).
\end{align*}
%We did not write the maps because at least one direction of every equivalence is induced by a natural map. 
This proves the proposition.
\end{proof}


\end{document}
